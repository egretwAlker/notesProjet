{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-distributed stochastic neighbor embedding (t-SNE)\n",
    "\n",
    "Object: Embed high-dimensional data for visualization in a low-dismensional space of 2 or 3 dimensions in such a way that similar (definition?) objects are modeled by nearby points and dissimilar objects are modeled by distant points with high probability.\n",
    "\n",
    "1. a probability distribution over pairs of high-dimensional objects in such a way that similar objects are assigned a higher probability while dissimilar points lower.\n",
    "2. t-SNE defines a similar probability distribution over the points in the low-dimensional map, and it minimizes the Kullback-Leibler divergence(?) between the 2 distributions with respect to the locations of the points in the map."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kullbackâ€“Leibler divergence\n",
    "\n",
    "$$\n",
    "D_{\\mathrm{KL}}(P \\| Q)=\\sum_{x \\in \\mathcal{X}} P(x) \\log \\left(\\frac{P(x)}{Q(x)}\\right)\n",
    "$$\n",
    "\n",
    "It is supposed to mesure the surprise from using Q as a model when the actual distribution is P.\n",
    "\n",
    "The surprise should be positive, indeed:\n",
    "\n",
    "$$\n",
    "\\sum P(k)\\log({P(k)\\over Q(k)}) \\ge \\sum P(x) (1 - {Q(x) \\over P(x)}) = 0\n",
    "$$\n",
    "\n",
    "It's the average difference of the number of bits required for encoding samples of P using a code optimized for Q rather than one optimized for P."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE details\n",
    "\n",
    "$$\n",
    "p_{j \\mid i}=\\frac{\\exp \\left(-\\left\\|\\mathbf{x}_i-\\mathbf{x}_j\\right\\|^2 / 2 \\sigma_i^2\\right)}{\\sum_{k \\neq i} \\exp \\left(-\\left\\|\\mathbf{x}_i-\\mathbf{x}_k\\right\\|^2 / 2 \\sigma_i^2\\right)}\n",
    "$$\n",
    "and set $p_{i \\mid i}=0$.\n",
    "\n",
    "The exp(...) thing is the Gaussian distribution.\n",
    "\n",
    "Now define\n",
    "$$\n",
    "p_{i j}=\\frac{p_{j \\mid i}+p_{i \\mid j}}{2 N}\n",
    "$$\n",
    "\n",
    "Note that $p{i i} = 0$ and $\\sum_{i j} p_{i j} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
